{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49157,
     "status": "ok",
     "timestamp": 1650860680935,
     "user": {
      "displayName": "Zoom Zhong",
      "userId": "11374017084540436764"
     },
     "user_tz": 240
    },
    "id": "DL6CeoW0LGIH",
    "outputId": "bd53389c-69da-430c-cbd4-076f91bfc376"
   },
   "outputs": [],
   "source": [
    "# !apt-get update\n",
    "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# !ls\n",
    "# !mkdir test\n",
    "# !rm -r test\n",
    "# !wget -q https://apache.osuosl.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
    "# !ls\n",
    "# !tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
    "# !pwd\n",
    "# !ls /content/\n",
    "\n",
    "# # Set up Spark\n",
    "# !pip install -q findspark\n",
    "# !pip install py4j\n",
    "# !pip install koalas\n",
    "\n",
    "# !export JAVA_HOME=$(/usr/lib/jvm/java-8-openjdk-amd64 -v 1.8)\n",
    "# ! echo $JAVA_HOME\n",
    "# import os\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
    "# import findspark\n",
    "# findspark.init(\"spark-3.2.1-bin-hadoop3.2\")# SPARK_HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 10052,
     "status": "ok",
     "timestamp": 1650860690973,
     "user": {
      "displayName": "Zoom Zhong",
      "userId": "11374017084540436764"
     },
     "user_tz": 240
    },
    "id": "qhMvPK1cQn1-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1650860984120,
     "user": {
      "displayName": "Zoom Zhong",
      "userId": "11374017084540436764"
     },
     "user_tz": 240
    },
    "id": "DzaVQ_d38yL4"
   },
   "outputs": [],
   "source": [
    "from pyspark import keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param, Params, TypeConverters\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import StringType\n",
    "# import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col,size,count,when,isnan, udf\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "from pyspark.ml.feature import ElementwiseProduct\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "class CustomTransformer(Transformer, HasInputCol, HasOutputCol, DefaultParamsReadable, DefaultParamsWritable):\n",
    "  input_col = Param(Params._dummy(), \"input_col\", \"input column name.\", typeConverter=TypeConverters.toString)\n",
    "  output_col = Param(Params._dummy(), \"output_col\", \"output column name.\", typeConverter=TypeConverters.toString)\n",
    "  \n",
    "  @keyword_only\n",
    "  def __init__(self, input_col: str = \"input\", output_col: str = \"output\"):\n",
    "    super(CustomTransformer, self).__init__()\n",
    "    self._setDefault(input_col=None, output_col=None)\n",
    "    kwargs = self._input_kwargs\n",
    "    self.set_params(**kwargs)\n",
    "    \n",
    "  @keyword_only\n",
    "  def set_params(self, input_col: str = \"input\", output_col: str = \"output\"):\n",
    "    kwargs = self._input_kwargs\n",
    "    self._set(**kwargs)\n",
    "    \n",
    "  def get_input_col(self):\n",
    "    return self.getOrDefault(self.input_col)\n",
    "  \n",
    "  def get_output_col(self):\n",
    "    return self.getOrDefault(self.output_col)\n",
    "  \n",
    "  def _transform(self, df: DataFrame):\n",
    "    input_col = self.get_input_col()\n",
    "    output_col = self.get_output_col()\n",
    "    # The custom action: concatenate the integer form of the doubles from the Vector\n",
    "    transform_udf = udf(lambda x: '/'.join([str(int(y)) for y in x]), StringType())\n",
    "    return df.withColumn(output_col, transform_udf(input_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1650860690976,
     "user": {
      "displayName": "Zoom Zhong",
      "userId": "11374017084540436764"
     },
     "user_tz": 240
    },
    "id": "VzxmXe4SOVJl"
   },
   "outputs": [],
   "source": [
    "class label_transformer(Transformer, HasInputCol, HasOutputCol, DefaultParamsReadable, DefaultParamsWritable):\n",
    "  input_col = Param(Params._dummy(), \"input_col\", \"input column name.\", typeConverter=TypeConverters.toString)\n",
    "  output_col = Param(Params._dummy(), \"output_col\", \"output column name.\", typeConverter=TypeConverters.toString)\n",
    "  \n",
    "  @keyword_only\n",
    "  def __init__(self, input_col: str = \"input\", output_col: str = \"output\"):\n",
    "    super(label_transformer, self).__init__()\n",
    "    self._setDefault(input_col=None, output_col=None)\n",
    "    kwargs = self._input_kwargs\n",
    "    self.set_params(**kwargs)\n",
    "    \n",
    "  @keyword_only\n",
    "  def set_params(self, input_col: str = \"input\", output_col: str = \"output\"):\n",
    "    kwargs = self._input_kwargs\n",
    "    self._set(**kwargs)\n",
    "    \n",
    "  def get_input_col(self):\n",
    "    return self.getOrDefault(self.input_col)\n",
    "  \n",
    "  def get_output_col(self):\n",
    "    return self.getOrDefault(self.output_col)\n",
    "  \n",
    "  def _transform(self, df: DataFrame):\n",
    "    input_col = self.get_input_col()\n",
    "    output_col = self.get_output_col()\n",
    "    # The custom action\n",
    "    df1 = df.withColumn(output_col, \\\n",
    "                           (when(col(input_col).like(\"%my dog%\"), 1) \\\n",
    "                           .when(col(input_col).like(\"%I have a dog%\"), 1) \\\n",
    "                           .when(col(input_col).like(\"%my cat%\"), 1) \\\n",
    "                           .when(col(input_col).like(\"%I have a cat%\"), 1) \\\n",
    "                           .when(col(input_col).like(\"%my puppy%\"), 1) \\\n",
    "                           .when(col(input_col).like(\"%my pup%\"), 1) \\\n",
    "                           .when(col(input_col).like(\"%my kitty%\"), 1) \\\n",
    "                           .when(col(input_col).like(\"%my pussy%\"), 1) \\\n",
    "                           .otherwise(0)))\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32072,
     "status": "ok",
     "timestamp": 1650860723034,
     "user": {
      "displayName": "Zoom Zhong",
      "userId": "11374017084540436764"
     },
     "user_tz": 240
    },
    "id": "4jjrdJJNvAS9",
    "outputId": "6c4838e5-50b5-49f0-9048-2fd0942d5a4d"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "data_path = \"test_2022-04-20.csv\"\n",
    "# data_path = \"drive/My Drive/20210401/TDI_youtube_comment/animals_comments.csv\"\n",
    "test_review = spark.read.format(\"csv\").option(\"header\", \"true\").load(data_path)\n",
    "# test_review.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1650860723882,
     "user": {
      "displayName": "Zoom Zhong",
      "userId": "11374017084540436764"
     },
     "user_tz": 240
    },
    "id": "lRkQ4kPUCcaX"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "class stem_transformer(Transformer, HasInputCol, HasOutputCol, DefaultParamsReadable, DefaultParamsWritable):\n",
    "  input_col = Param(Params._dummy(), \"input_col\", \"input column name.\", typeConverter=TypeConverters.toString)\n",
    "  output_col = Param(Params._dummy(), \"output_col\", \"output column name.\", typeConverter=TypeConverters.toString)\n",
    "  \n",
    "  @keyword_only\n",
    "  def __init__(self, input_col: str = \"input\", output_col: str = \"output\"):\n",
    "    super(stem_transformer, self).__init__()\n",
    "    self._setDefault(input_col=None, output_col=None)\n",
    "    kwargs = self._input_kwargs\n",
    "    self.set_params(**kwargs)\n",
    "    \n",
    "  @keyword_only\n",
    "  def set_params(self, input_col: str = \"input\", output_col: str = \"output\"):\n",
    "    kwargs = self._input_kwargs\n",
    "    self._set(**kwargs)\n",
    "    \n",
    "  def get_input_col(self):\n",
    "    return self.getOrDefault(self.input_col)\n",
    "  \n",
    "  def get_output_col(self):\n",
    "    return self.getOrDefault(self.output_col)\n",
    "  \n",
    "  def _transform(self, df: DataFrame):\n",
    "    input_col = self.get_input_col()\n",
    "    output_col = self.get_output_col()\n",
    "\n",
    "    # Instantiate stemmer object\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    # Create stemmer python function\n",
    "    def stem(in_vec):\n",
    "        out_vec = []\n",
    "        for t in in_vec:\n",
    "            t_stem = stemmer.stem(t)\n",
    "            if len(t_stem) > 1:\n",
    "                out_vec.append(t_stem)       \n",
    "        return out_vec\n",
    "\n",
    "    # Create user defined function for stemming with return type Array<String>\n",
    "    stemmer_udf = udf(lambda x: stem(x), ArrayType(StringType()))\n",
    "\n",
    "    # Create new column with vectors containing the stemmed tokens \n",
    "    df1 = df.withColumn(output_col, stemmer_udf(input_col))\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1650860723883,
     "user": {
      "displayName": "Zoom Zhong",
      "userId": "11374017084540436764"
     },
     "user_tz": 240
    },
    "id": "si-IiYOqLNHg"
   },
   "outputs": [],
   "source": [
    "# from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\n",
    "\n",
    "# persistedModel = LogisticRegressionModel.load(\"drive/My Drive/20210401/TDI_youtube_comment/lr_best_model\")\n",
    "# predictions = persistedModel.transform(df_model)\n",
    "# predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 8290,
     "status": "ok",
     "timestamp": 1650860732168,
     "user": {
      "displayName": "Zoom Zhong",
      "userId": "11374017084540436764"
     },
     "user_tz": 240
    },
    "id": "KoSZN5Wzt3vv"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier, GBTClassificationModel\n",
    "persistedModel = GBTClassificationModel.load(\"gbt_best_model\")\n",
    "# persistedModel = GBTClassificationModel.load(\"drive/My Drive/20210401/TDI_youtube_comment/gbt_best_model\")\n",
    "# predictions = persistedModel.transform(df_model)\n",
    "# predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1650860870431,
     "user": {
      "displayName": "Zoom Zhong",
      "userId": "11374017084540436764"
     },
     "user_tz": 240
    },
    "id": "YH9o-_jfMuAX"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, Word2Vec\n",
    "\n",
    "custom_transformer = label_transformer(input_col=\"comment\", output_col=\"label\")\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"comment\", outputCol=\"text\", pattern=\"\\\\W\")\n",
    "remover = StopWordsRemover(inputCol=\"text\", outputCol=\"vector_no_stopw\")\n",
    "custom_transformer1 = stem_transformer(input_col=\"vector_no_stopw\", output_col=\"vector_stemmed\")\n",
    "word2Vec = Word2Vec(vectorSize=50, minCount=1, inputCol=\"vector_stemmed\", outputCol=\"wordVector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8245,
     "status": "ok",
     "timestamp": 1650860997122,
     "user": {
      "displayName": "Zoom Zhong",
      "userId": "11374017084540436764"
     },
     "user_tz": 240
    },
    "id": "LQt6pZniM83K",
    "outputId": "0ef77952-3938-4db4-ee93-35a2604876c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|        creator_name|              userid|             comment|label|                text|     vector_no_stopw|      vector_stemmed|          wordVector|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|         Shiki Amabe|Ugh2nz-8o6JNLXgCoAEC|i'm 100% a cat pe...|    0|[i, m, 100, a, ca...|[m, 100, cat, per...|[100, cat, person...|[0.01140446082146...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|           Animalist|UgjRhSL--aI5NHgCoAEC|Nothing sounds cu...|    0|[nothing, sounds,...|[nothing, sounds,...|[noth, sound, cut...|[0.00233010696247...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|  Charlie The Beagle|UgjSdp5cizW6bngCoAEC|   I want them all:)|    0|[i, want, them, all]|              [want]|              [want]|[-0.0023084036074...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|    Baby Cute Cat BD|Ugw-05B_-5d9TvJU7...|        Wow so cute |    0|     [wow, so, cute]|         [wow, cute]|         [wow, cute]|[0.01148698874749...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|   Sebastian Cabrera|Ugw-B5Ln9G0Qgiv1Y...|0:37 I love this ...|    0|[0, 37, i, love, ...|[0, 37, love, par...|[37, love, part, ...|[0.00436426475644...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|     muharrem salihu|Ugw-pZBsNNC8KhO2u...|shum.te bukra si ...|    0|[shum, te, bukra,...|[shum, te, bukra,...|[shum, te, bukra,...|[-0.0010271301202...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|        Angel Denise|Ugw0I_DUHTPip8RNf...|Awe!! That's ador...|    0|[awe, that, s, ad...|[awe, adorable, l...|   [awe, ador, love]|[0.00483263361578...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|Renata Lilian Pra...|Ugw0NF0iqkdQRuPdO...|                FOFO|    0|              [fofo]|              [fofo]|              [fofo]|[-3.7529069231823...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|             Jay Sen|Ugw0WZtFLRNeujozn...|       So cute......|    0|          [so, cute]|              [cute]|              [cute]|[0.01777485013008...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|            Ujoni C.|Ugw0lYo42cdD_swoI...|3:41 Asian parent...|    0|[3, 41, asian, pa...|[3, 41, asian, pa...|[41, asian, paren...|[0.00230967206880...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|        realvibeonly|Ugw13RSjISmklNT_M...|      OMG had me lol|    0| [omg, had, me, lol]|          [omg, lol]|          [omg, lol]|[0.00139259849674...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|             B Right|Ugw1B6IUKtSpy8-5Q...|I wish this was i...|    0|[i, wish, this, w...|   [wish, high, def]|   [wish, high, def]|[-9.1616933544476...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|      mundo da nanda|Ugw1GytaoQi7jWlUS...|           Que fofo |    0|         [que, fofo]|         [que, fofo]|         [que, fofo]|[0.00385521979478...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|            Jackie V|Ugw1M4YPwXlnCZ0Ri...|Calm down, I was ...|    0|[calm, down, i, w...|[calm, playing, c...|[calm, play, cuteee]|[-0.0012464728206...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|      Jany Ros chota|Ugw1aEyek11DgJnZu...|              Bonito|    0|            [bonito]|            [bonito]|            [bonito]|[0.00696676177904...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|         FlameHaze59|Ugw1hW_2tbNVMW9v4...|Awww, I'm crying,...|    0|[awww, i, m, cryi...|[awww, m, crying,...|[awww, cri, cute,...|[0.00761824622750...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|       Kamini Bansal|Ugw1m3HkXsPRvfHRN...|Too cute i can't ...|    1|[too, cute, i, ca...|[cute, stop, tear...|[cute, stop, tear...|[0.01242436347529...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|        Johnny Adame|Ugw22DI3kd-_H5MyB...|Well, now they ha...|    0|[well, now, they,...|   [well, meal, lol]|   [well, meal, lol]|[-5.7519398008783...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|            luna_lou|Ugw29fjiMBgdNeGJz...|Played this for m...|    1|[played, this, fo...|[played, cat, sto...|[play, cat, stone...|[0.00445757148554...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|  Ythan Paul Legaspi|Ugw2I89r4p5tt2hRf...|         Thats cute |    0|       [thats, cute]|       [thats, cute]|        [that, cute]|[0.01181038585491...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[custom_transformer, regexTokenizer,remover, custom_transformer1, word2Vec, persistedModel])\n",
    "model = pipeline.fit(test_review)\n",
    "results = model.transform(test_review)\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1865,
     "status": "ok",
     "timestamp": 1650861029390,
     "user": {
      "displayName": "Zoom Zhong",
      "userId": "11374017084540436764"
     },
     "user_tz": 240
    },
    "id": "x4_qFap2P1nR",
    "outputId": "afb135d6-40b0-45fe-ee27-2cb84b5d4a88"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/3202129377.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNum_Pos_Label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNum_Pos_Label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "Num_Pos_Label = results.filter(F.col('prediction') == 1.0).count() \n",
    "print(Num_Pos_Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 976,
     "status": "ok",
     "timestamp": 1650861031973,
     "user": {
      "displayName": "Zoom Zhong",
      "userId": "11374017084540436764"
     },
     "user_tz": 240
    },
    "id": "HGeOEyDeR4zD",
    "outputId": "d69f021a-b67f-47c1-b983-b2bd990080b8"
   },
   "outputs": [],
   "source": [
    "final_result = results.select(['creator_name', 'userid']).where((results[\"label\"] == 1) | (results[\"prediction\"] == 1.0))\n",
    "final_result.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNwXSLFcnB6eY5GYVhHhP6I",
   "collapsed_sections": [],
   "name": "youtube_cat_dog_pipeline_v3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
